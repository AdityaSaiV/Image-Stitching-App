{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6fb1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "\n",
    "anvil.server.connect(\"server_3UAL3FGB2TQVS6ILQVCKL4N5-4VSIRZSYHB3T5CXQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81bb24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import load_img\n",
    "import anvil.server\n",
    "import anvil.media\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "@anvil.server.callable\n",
    "def image_stitch(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        img = load_img(filename)\n",
    "        img.save('Query.jpg')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdf62334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import load_img\n",
    "import anvil.server\n",
    "import anvil.media\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "@anvil.server.callable\n",
    "def image_stitch2(file):\n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        img2 = load_img(filename)\n",
    "        img2.save('Train.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1621393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import load_img\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import anvil.server\n",
    "import anvil.media\n",
    "\n",
    "@anvil.server.callable\n",
    "def stitching_function():\n",
    "    train_photo = cv2.imread('./' + 'Train.jpg')\n",
    "    train_photo = cv2.cvtColor(train_photo, cv2.COLOR_BGR2RGB)\n",
    "    train_photo_gray = cv2.cvtColor(train_photo, cv2.COLOR_RGB2GRAY)\n",
    "    query_photo = cv2.imread('./' + 'Query.jpg')\n",
    "    query_photo = cv2.cvtColor(query_photo, cv2.COLOR_BGR2RGB)\n",
    "    query_photo_gray = cv2.cvtColor(query_photo, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    def select_descriptor_methods(image, method=None):    \n",
    "        if method == 'sift':\n",
    "            descriptor = cv2.SIFT_create()\n",
    "        elif method == 'surf':\n",
    "            descriptor = cv2.SURF_create()\n",
    "        elif method == 'brisk':\n",
    "            descriptor = cv2.BRISK_create()\n",
    "        elif method == 'orb':\n",
    "            descriptor = cv2.ORB_create()\n",
    "\n",
    "        (keypoints, features) = descriptor.detectAndCompute(image, None)\n",
    "        return (keypoints, features)\n",
    "\n",
    "    keypoints_train_img, features_train_img = select_descriptor_methods(train_photo_gray, method='sift')\n",
    "    keypoints_query_img, features_query_img = select_descriptor_methods(query_photo_gray, method='sift')\n",
    "\n",
    "    for keypoint in keypoints_query_img:\n",
    "        x,y = keypoint.pt\n",
    "        size = keypoint.size \n",
    "        orientation = keypoint.angle\n",
    "        response = keypoint.response \n",
    "        octave = keypoint.octave\n",
    "        class_id = keypoint.class_id\n",
    "\n",
    "    keypoint_train = cv2.drawKeypoints(train_photo_gray, keypoints_train_img, None, color=(0, 255, 0))\n",
    "    keypoint_query = cv2.drawKeypoints(query_photo_gray, keypoints_query_img, None, color=(0, 255, 0))\n",
    "    \n",
    "    keypoint_train = cv2.cvtColor( keypoint_train, cv2.COLOR_BGR2RGB)\n",
    "    keypoint_query = cv2.cvtColor(keypoint_query, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cv2.imwrite('keypoint_train.jpg',keypoint_train)\n",
    "    cv2.imwrite('keypoint_query.jpg',keypoint_query)\n",
    "\n",
    "    def create_matching_object(method,crossCheck):\n",
    "        if method == 'sift' or method == 'surf':\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=crossCheck)\n",
    "        elif method == 'orb' or method == 'brisk':\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=crossCheck)\n",
    "        return bf\n",
    "\n",
    "    def key_points_matching(features_train_img, features_query_img, method):\n",
    "        bf = create_matching_object(method, crossCheck=True)\n",
    "        best_matches = bf.match(features_train_img,features_query_img)\n",
    "        rawMatches = sorted(best_matches, key = lambda x:x.distance)\n",
    "        #print(\"Raw matches with Brute force):\", len(rawMatches))\n",
    "        return rawMatches\n",
    "\n",
    "    def key_points_matching_KNN(features_train_img, features_query_img, ratio, method):\n",
    "        bf = create_matching_object(method, crossCheck=False)\n",
    "        rawMatches = bf.knnMatch(features_train_img, features_query_img, k=2)\n",
    "        #print(\"Raw matches (knn):\", len(rawMatches))\n",
    "        matches = []\n",
    "        for m,n in rawMatches:\n",
    "            if m.distance < n.distance * ratio:\n",
    "                matches.append(m)\n",
    "        return matches\n",
    "\n",
    "    feature_to_match = 'knn'\n",
    "    feature_extraction_algo = 'sift'\n",
    "    #print(\"Drawing: {} matched features Lines\".format(feature_to_match))\n",
    "    if feature_to_match == 'bf':\n",
    "        matches = key_points_matching(features_train_img, features_query_img, method=feature_extraction_algo) \n",
    "        mapped_features_image = cv2.drawMatches(train_photo,keypoints_train_img,query_photo,keypoints_query_img,matches[:100],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    elif feature_to_match == 'knn':\n",
    "        matches = key_points_matching_KNN(features_train_img, features_query_img, ratio=0.75, method=feature_extraction_algo)\n",
    "        mapped_features_image_knn = cv2.drawMatches(train_photo, keypoints_train_img, query_photo, keypoints_query_img, np.random.choice(matches,100),None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    mapped = cv2.cvtColor( mapped_features_image_knn, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite('knn_match.jpg',mapped)\n",
    "    \n",
    "    \n",
    "    def homography_stitching(keypoints_train_img, keypoints_query_img, matches, reprojThresh):   \n",
    "\n",
    "        keypoints_train_img = np.float32([keypoint.pt for keypoint in keypoints_train_img])\n",
    "        keypoints_query_img = np.float32([keypoint.pt for keypoint in keypoints_query_img])\n",
    "        if len(matches) > 4:\n",
    "            points_train = np.float32([keypoints_train_img[m.queryIdx] for m in matches])\n",
    "            points_query = np.float32([keypoints_query_img[m.trainIdx] for m in matches])\n",
    "            (H, status) = cv2.findHomography(points_train, points_query, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "            return (matches, H, status)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    M = homography_stitching(keypoints_train_img, keypoints_query_img, matches, reprojThresh=4)\n",
    "\n",
    "    if M is None:\n",
    "        print(\"Error!\")\n",
    "\n",
    "    (matches, Homography_Matrix, status) = M\n",
    "\n",
    "\n",
    "    width = query_photo.shape[1] + train_photo.shape[1]\n",
    "    height = max(query_photo.shape[0], train_photo.shape[0])\n",
    "    result = cv2.warpPerspective(train_photo, Homography_Matrix,  (width, height))\n",
    "    result[0:query_photo.shape[0], 0:query_photo.shape[1]] = query_photo\n",
    "    \n",
    "    result = cv2.cvtColor( result, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite('final.jpg',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3790b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "import anvil.media\n",
    "import io\n",
    "from PIL import Image\n",
    "@anvil.server.callable\n",
    "def keypoint_image1():\n",
    "    image = Image.open('keypoint_train.jpg')\n",
    "    bs=io.BytesIO()\n",
    "    name = 'image_result'\n",
    "    image.save(bs,format='png')\n",
    "    return anvil.BlobMedia('image/png',bs.getvalue(),name=name)\n",
    "@anvil.server.callable\n",
    "def keypoint_image2():\n",
    "    image = Image.open('keypoint_query.jpg')\n",
    "    bs=io.BytesIO()\n",
    "    name = 'image_result'\n",
    "    image.save(bs,format='png')\n",
    "    return anvil.BlobMedia('image/png',bs.getvalue(),name=name)\n",
    "@anvil.server.callable\n",
    "def knn_match():\n",
    "    image = Image.open('knn_match.jpg')\n",
    "    bs=io.BytesIO()\n",
    "    name = 'image_result'\n",
    "    image.save(bs,format='png')\n",
    "    return anvil.BlobMedia('image/png',bs.getvalue(),name=name)\n",
    "@anvil.server.callable\n",
    "def final():\n",
    "    image = Image.open('final.jpg')\n",
    "    bs=io.BytesIO()\n",
    "    name = 'image_result'\n",
    "    image.save(bs,format='png')\n",
    "    return anvil.BlobMedia('image/png',bs.getvalue(),name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4cbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
